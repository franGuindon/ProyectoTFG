\documentclass[12pt,oneside]{book}
\usepackage[letterpaper, total={19cm, 20cm}]{geometry}

\usepackage{graphicx}
\usepackage{csquotes}
\usepackage[backend=biber,              % Use biber/biblatex
            style=ieee,
            sorting=none,
            citestyle=numeric-comp]{biblatex}
\usepackage{array, multirow}
\usepackage{caption}
\usepackage{subcaption}

\addbibresource{../tesis/literatura.bib}
\input{../tesis/code_blocks.tex}


\begin{document}
 \graphicspath{{./}{../tesis/fig/}}
  Tecnológico de Costa Rica
  \par\vspace{1mm}
  Escuela de Ingeniería Electrónica
  \par\vspace{1mm}
  Programa de Licenciatura en Ingeniería Electrónica
  \par\vspace{10mm}
  Trabajo Final de Graduación
  \par\vspace{1mm}
  Francis Guindon Badilla
  \par\vspace{1mm}
  2018259419
  \par\vspace{10mm}
  \large\textbf{Bitácora - Semana 4}
  \par\vspace{10mm}
  \small

  \begin{table} [!h]
    \centering
    \small
    \begin{tabular}{p{1.5 cm} p{2.1 cm} p{5 cm} p{8 cm}}
      \hline
      Fecha & Duración & Actividad & Descripción \\
      \hline
      8/3/23 & 1 h & Reunión de avance 5 & \\
      \hline
      \textbf{Total} & 21 h \\
      \hline
    \end{tabular}
  \end{table}
  
  \vfill

  \begin{tabular}{p{3 cm} p{10 cm}}
    Firma profesor: & \\
    \cline{2-2}
  \end{tabular}

  \newpage

  \section{Notas}
  \setlength\parindent{0pt}

  \subsection{Notes from meeting}

  Sugerencias del profe:
  \begin{enumerate}
    \item La información relativa entre bloques es posiblemente importante
    \item Agregar como features diferencias entre propio y vecinos (mean y var)
    \item Agregar mean y var del bloque en sí, agregar de vecinos
    \item Entonces el featv debería verse así:
    \item 64 feats (bordes), 64 feats (diffs entre bordes y mean/var propio), 2 feats mean var propio : total 130
    \item Should dataset be balanced for trees? (investigate)
    \item Idea del profe: Since we have many more negative samples than positive, could it be that each tree is improved if trained on bootstrapped positive samples but random samples of the negative set.
  \end{enumerate}

  Metas de la semana:
  \begin{enumerate}
    \item Agregar y entrenar con nuevos features
    \item Terminar funcion de Ranger
    \item Investigar porcentaje comun de perdida en h264 streaming
  \end{enumerate}

  
  \begin{lstlisting}
francis@francis-laptop:~$ python3
Python 3.8.10 (default, Nov 14 2022, 12:59:47) 
[GCC 9.4.0] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>> VCC = 3.3
>>> VLED = 2
>>> I=0.02
>>> VR = VCC-VLED
>>> VR
1.2999999999999998
>>> R = VR/I
>>> R
64.99999999999999
>>> resistor_colors = ['black', 'brown','red','orange','yellow', 'green','blue','violet','gray','white']
>>> R
64.99999999999999
>>> lambda n: rint(n+0.5)
<function <lambda> at 0x7fca35a40280>
>>> rint = lambda n: int(n+0.5)
>>> rint(R)
65
>>> R = rint(R)
>>> units = lambda n: n%10
>>> tens = lambda n: (n//10)%10
>>> units(R)
5
>>> tens(R)
6
>>> rcolor_units = lambda r: resustor_colors[units(r)]
>>> rcolor_units = lambda r: resistor_colors[units(r)]
>>> rcolor_units(R)
'green'
>>> rcolor_tens = lambda r: resistor_colors[tens(r)]
>>> rcolor_tens(R)
'blue'
>>> rcolor_mantissa = lambda r: rcolor_tens, rcolor_units
>>> rcolor_mantissa(R)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: 'tuple' object is not callable
>>> rcolor_mantissa = lambda r: (rcolor_tens, rcolor_units)
>>> rcolor_mantissa(R)
(<function <lambda> at 0x7fca35a40430>, <function <lambda> at 0x7fca35a404c0>)
>>> rcolor_mantissa = lambda r: (rcolor_tens(r), rcolor_units(r))
>>> rcolor_mantissa(R)
('blue', 'green')
>>> import math
>>> help(math.log)

>>> rcolor_mantissa(R)
('blue', 'green')
>>> 
  \end{lstlisting}

  \subsubsection*{1:34 P.M. 12/3/23 Ranger Function}
  \begin{enumerate}
    \item Setup Ranger as Meson Library Estimate: 2H Real: 
    \begin{enumerate}
      \item Create meson struct such that it supports builds of different parts of the project
    \end{enumerate}
  \end{enumerate}

  Link to Trello: \url{https://trello.com/invite/tfg73340775/ATTI3bca876e93443792ef5bb2cde6af9078BDECA8E7}

  Trello card: Compile Ranger with meson

  Goal: fix ranger\_atom meson build ... done \\
  Goal: fix linking with utility  ... done \\
  Goal: fix \url{../utility/Data.cpp:152:6: error} ... \\
  Error: I changed Data.h file without noticing \\
  How I found solution: I looked at the git and noticed the file had changed
  Which git?
  I have deactivated ranger git over my own \\
  Goal: fix linking with Forest ... done \\
  Goal: fix linking with Tree ... done \\
  Goal: fix Forest compilation \url{../Forest/ForestProbability.cpp:36:85: error} ... done \\
  Goal: I might have just compiled ranger with meson \\
  Goal: Test ranger bin help ... done \\
  Goal: Test ranger bin train ... done \\

  Trello card: Compile Ranger with selective ranger duplicates (stored in tfg src dir)

  Goal: build ranger from next meson build ... done \\
  Goal: build ranger from root meson build ... done \\
  Goal: copy source file I intend to start with ... done \\
  Goal: add dir to meson build ... done \\
  Goal: add files to ranger build ... done \\
  
  Trello card: Write minimal loader

  % how (in_progress start_time) = (... 07:29 P.M. 14/3/23) looks like
  % how (done 07:29 P.M. 14/3/23) looks like
  Goal: add custom logging in the loader location (... 07:29 P.M. 14/3/23) \\
  Goal: add custom loader code and watch it fail \\ 
  Goal: fix compilation issues \\
  
  ...

  Goal: start changing the code ... \\


  \begin{lstlisting}
    francis@francis-laptop:~/Documents/2023_S1/Proyecto/subprojects/ranger/cpp_version/src/build (main=)$ ./ranger -h
    Usage: 
        ./ranger [options]
    
    Options:
        --help                        Print this help.
        --version                     Print version and citation information.
        --verbose                     Turn on verbose mode.
        --file FILE                   Filename of input data. Only numerical values are supported.
        --treetype TYPE               Set tree type to:
                                      TYPE = 1: Classification.
                                      TYPE = 3: Regression.
                                      TYPE = 5: Survival.
                                      (Default: 1)
        --probability                 Grow a Classification forest with probability estimation for the classes.
                                      Use in combination with --treetype 1.
        --depvarname NAME             Name of dependent variable. For survival trees this is the time variable.
        --statusvarname NAME          Name of status variable, only applicable for survival trees.
                                      Coding is 1 for event and 0 for censored.
        --ntree N                     Set number of trees to N.
                                      (Default: 500)
        --mtry N                      Number of variables to possibly split at in each node.
                                      (Default: sqrt(p) with p = number of independent variables)
        --targetpartitionsize N       Set minimal node size to N.
                                      For Classification and Regression growing is stopped if a node reaches a size smaller than N.
                                      For Survival growing is stopped if one child would reach a size smaller than N.
                                      This means nodes with size smaller N can occur for Classification and Regression.
                                      (Default: 1 for Classification, 5 for Regression, and 3 for Survival)
        --maxdepth N                  Set maximal tree depth to N.
                                      Set to 0 for unlimited depth. A value of 1 corresponds to tree stumps (1 split).
        --catvars V1,V2,..            Comma separated list of names of (unordered) categorical variables. 
                                      Categorical variables must contain only positive integer values.
        --write                       Save forest to file <outprefix>.forest.
        --predict FILE                Load forest from FILE and predict with new data. The new data is expected in the exact same 
                                      shape as the training data. If the outcome of your new dataset is unknown, add a dummy column.
        --predall                     Return a matrix with individual predictions for each tree instead of aggregated 
                                      predictions for all trees (classification and regression only).
        --predictiontype TYPE         Set type of prediction to:
                                      TYPE = 1: Return predicted classes or values.
                                      TYPE = 2: Return terminal node IDs per tree for new observations.
                                      (Default: 1)
        --impmeasure TYPE             Set importance mode to:
                                      TYPE = 0: none.
                                      TYPE = 1: Node impurity: Gini for Classification, variance for Regression, sum of test statistic for Survival.
                                      TYPE = 2: Permutation importance, scaled by standard errors.
                                      TYPE = 3: Permutation importance, no scaling.
                                      TYPE = 5: Corrected node impurity: Bias-corrected version of node impurity importance.
                                      TYPE = 6: Local (casewise) permutation importance.
                                      (Default: 0)
        --noreplace                   Sample without replacement.
        --fraction X                  Fraction of observations to sample. Default is 1 for sampling with replacement 
                                      and 0.632 for sampling without replacement.
        --splitrule RULE              Splitting rule:
                                      RULE = 1: Gini for Classification, variance for Regression, logrank for Survival.
                                      RULE = 2: AUC for Survival, not available for Classification and Regression.
                                      RULE = 3: AUC (ignore ties) for Survival, not available for Classification and Regression.
                                      RULE = 4: MAXSTAT for Survival and Regression, not available for Classification.
                                      RULE = 5: ExtraTrees for all tree types.
                                      RULE = 6: BETA for regression, only for (0,1) bounded outcomes.
                                      RULE = 7: Hellinger for Classification, not available for Regression and Survival.
                                      (Default: 1)
        --randomsplits N              Number of random splits to consider for each splitting variable (ExtraTrees splitrule only).
        --alpha VAL                   Significance threshold to allow splitting (MAXSTAT splitrule only).
        --minprop VAL                 Lower quantile of covariate distribtuion to be considered for splitting (MAXSTAT splitrule only).
        --caseweights FILE            Filename of case weights file.
        --holdout                     Hold-out mode. Hold-out all samples with case weight 0 and use these for variable 
                                      importance and prediction error.
        --splitweights FILE           Filename of split select weights file.
        --alwayssplitvars V1,V2,..    Comma separated list of variable names to be always considered for splitting.
        --regcoef r1,r2,..            Comma separated list of regularization coefficients (one for all variables or one for each variable).
        --usedepth                    Use node depth for regularization.
        --skipoob                     Skip computation of OOB error.
        --nthreads N                  Set number of parallel threads to N.
                                      (Default: Number of CPUs available)
        --seed SEED                   Set random seed to SEED.
                                      (Default: No seed)
        --outprefix PREFIX            Prefix for output files.
        --memmode MODE                Set memory mode to:
                                      MODE = 0: double.
                                      MODE = 1: float.
                                      MODE = 2: char.
                                      (Default: 0)
        --savemem                     Use memory saving (but slower) splitting mode.
    
    See README file for details and examples.
  \end{lstlisting}

  \begin{lstlisting}
francis@francis-laptop:~/Documents/2023_S1/Proyecto/subprojects/ranger/cpp_version/src/build$ ./ranger --verbose --file test_data.dat --depvarname y --treetype 1 --ntree 1000 --nthreads 12
Starting Ranger.
Loading input file: test_data.dat.
Growing trees ..
Computing prediction error ..

Tree type:                         Classification
Dependent variable name:           y
Number of trees:                   1000
Sample size:                       400
Number of independent variables:   2
Mtry:                              1
Target node size:                  1
Variable importance mode:          0
Memory mode:                       0
Seed:                              0
Number of threads:                 12

Overall OOB prediction error:      0.0025

Saved confusion matrix to file ranger_out.confusion.
Finished Ranger.
  \end{lstlisting}

  \begin{lstlisting}
francis@francis-laptop:~/Documents/2023_S1/Proyecto/subprojects/ranger/cpp_version/src/build$ cat ranger_out.confusion 
Overall OOB prediction error (Fraction missclassified): 0.0025

Class specific prediction errors:
                0     1
predicted 0     222   1     
predicted 1     0     177 
  \end{lstlisting}

  \printbibliography[title={Bibliografía},heading=bibintoc]
\end{document}
